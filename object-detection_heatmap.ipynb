{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "import argparse\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse input args\n",
    "'''argsParser = argparse.ArgumentParser(description=\"Apply object detection to the input video\")\n",
    "argsParser.add_argument(\"-m\", \"--model\", required=True, help=\"path of model for detection\")\n",
    "argsParser.add_argument(\"-i\", \"--input_dir\", required=True, help=\"path to input dir\")\n",
    "argsParser.add_argument(\"-o\", \"--output_dir\", required=True, help=\"path to output dir\")\n",
    "argsParser.add_argument(\"-y\", \"--yolo\", required=True, help=\"base path to YOLO directory\")\n",
    "argsParser.add_argument(\"-c\", \"--confidence\", type=float, default=0.5, help=\"min prob to filter weak detections\")\n",
    "args = vars(argsParser.parse_args())'''\n",
    "\n",
    "# set constants\n",
    "MODEL_PATH = 'yolo-keras.h5' #args[\"model\"]\n",
    "INPUT_DIR = '/home/ubuntu/valerio/data/restaurants-videos'#args['input_dir']\n",
    "OUTPUT_DIR = 'ccc'#args['output_dir']\n",
    "YOLO_DIR = 'yolo-coco'#args['yolo']\n",
    "CLASS_THRESHOLD = 0.5#args['confidence']\n",
    "WEIGHTS_PATH = os.path.join(YOLO_DIR, 'yolov3.weights')\n",
    "with open(os.path.join(YOLO_DIR, \"coco.names\")) as f:\n",
    "    lines = f.readlines()\n",
    "    LABELS = [e.strip() for e in lines]\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT = 416, 416\n",
    "YOLOV3_ANCHORS = [[116, 90, 156, 198, 373, 326],[30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]\n",
    "\n",
    "# create output dir (remove if it exists)\n",
    "if os.path.isdir(OUTPUT_DIR):\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolo model\n",
    "model = load_model(MODEL_PATH)\n",
    "print(\"[INFO] Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start processing one vide at a time\n",
    "for cam_dir in os.listdir(INPUT_DIR):\n",
    "    for video_file in os.listdir(os.path.join(INPUT_DIR, cam_dir)):    \n",
    "        start_time = time.time()\n",
    "        print(\"[INFO] processing %s ...\" % os.path.join(INPUT_DIR, cam_dir, video_file), end='', flush=True)\n",
    "\n",
    "        intial_W, initial_H = None, None\n",
    "        X, Y = [], []\n",
    "        vs = cv2.VideoCapture(os.path.join(INPUT_DIR, video_file))\n",
    "        #k=0\n",
    "        while True:\n",
    "            #t1=time.time()\n",
    "            (grabbed, frame) = vs.read()\n",
    "\n",
    "            # grabbed is False when no more frames are available\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            # save orinal size of each frame\n",
    "            if intial_W is None or initial_H is None:\n",
    "                initial_H, initial_W = frame.shape[:2]\n",
    "\n",
    "            # adapt the frame to the yolov3 network architecture (and normalize it)\n",
    "            frame = cv2.resize(frame, (YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "            frame = frame.astype('float32') / 255.0\n",
    "            frame = np.expand_dims(frame, 0)\n",
    "\n",
    "            # run prediction\n",
    "            yhat = model.predict(frame)\n",
    "\n",
    "            # analyze output to retrieve boxes\n",
    "            boxes = []\n",
    "            for i in range(len(yhat)):\n",
    "                boxes += utils.decode_netout(yhat[i][0], YOLOV3_ANCHORS[i], CLASS_THRESHOLD, YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT)\n",
    "\n",
    "            # scale boxes in order to fit the initial size of the frame\n",
    "            utils.correct_yolo_boxes(boxes, initial_H, initial_W, YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT)\n",
    "\n",
    "            # keep only boxes (predicted label and its score) above the confidence threshold\n",
    "            v_boxes, v_labels, v_scores = utils.get_boxes(boxes, LABELS, CLASS_THRESHOLD)\n",
    "\n",
    "            # analyze remaining boxes:\n",
    "            # - keep only the ones associaed with a person\n",
    "            # - save the coordinates of the centre of each box\n",
    "            for i in range(len(v_boxes)):\n",
    "                if v_labels[i] == 'person':\n",
    "                    y1, x1, y2, x2 = v_boxes[i].ymin, v_boxes[i].xmin, v_boxes[i].ymax, v_boxes[i].xmax\n",
    "                    X.append(x1 + (x2 - x1) / 2)\n",
    "                    Y.append(y1 + (y2 - y1) / 2)\n",
    "\n",
    "            #print(time.time()-t1)\n",
    "\n",
    "        # compute the size of figures in a way that it is proportional to the one of each frame\n",
    "        UNIT = 10\n",
    "        if initial_W > initial_H:\n",
    "            fig_height = UNIT\n",
    "            fig_width = UNIT * (initial_W / initial_H)\n",
    "        else:\n",
    "            fig_width = UNIT\n",
    "            fig_height = UNIT * (initial_H / initial_W)\n",
    "\n",
    "        # extract the filename from the full path\n",
    "        filename = video_file.split('.')[0]\n",
    "\n",
    "        # draw scatterplot\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        plt.scatter(X, Y)\n",
    "        plt.ylim([0, initial_H])\n",
    "        plt.xlim([0, initial_W])\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, filename + '-scatter.pdf'))\n",
    "\n",
    "        # draw heatmap\n",
    "        BINS = 20\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        plt.hist2d(X, Y, bins=25, range= [[0, initial_W], [0, initial_H]], density=True, cmap='Blues')\n",
    "        #plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(OUTPUT_DIR, filename + '-heatmap.pdf'))\n",
    "\n",
    "        print(\"DONE! It took %f seconds.\" % (time.time() - start_time), flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_virtenv",
   "language": "python",
   "name": "yolo_virtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
