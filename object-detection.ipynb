{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# import Yolo2Keras as y2k\n",
    "from tensorflow.keras.models import load_model\n",
    "import utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(1234)\n",
    "\n",
    "argsParser = argparse.ArgumentParser(description=\"Apply object detection to the input video\")\n",
    "argsParser.add_argument(\"-i\", \"--input\", required=True, help=\"path to input video\")\n",
    "argsParser.add_argument(\"-y\", \"--yolo\", required=True, help=\"base path to YOLO directory\")\n",
    "argsParser.add_argument(\"-c\", \"--confidence\", type=float, default=0.5, help=\"min prob to filter weak detections\")\n",
    "argsParser.add_argument(\"-t\", \"--threshold\", type=float, default=0.3, help=\"non-maxima suppression threshold\")\n",
    "args = vars(argsParser.parse_args())\n",
    "\n",
    "WEIGHTS_PATH = os.path.join(args['yolo'], 'yolov3.weights')\n",
    "INPUT_FILE = args['input']\n",
    "OUTPUT_FILE = INPUT_FILE.split('.')[0] + '-detected.avi'\n",
    "CLASS_THRESHOLD = args['confidence']\n",
    "NMS_THRESHOLD = args['threshold']\n",
    "YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT = 416, 416\n",
    "YOLOV3_ANCHORS = [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]\n",
    "with open(\"yolo-coco/coco.names\") as f:\n",
    "    lines = f.readlines()\n",
    "    LABELS = [e.strip() for e in lines]\n",
    "\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "\n",
    "vs = cv2.VideoCapture(INPUT_FILE)\n",
    "writer = None\n",
    "(W, H) = (None, None)\n",
    "\n",
    "try:\n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() else cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int(vs.get(prop))\n",
    "    print(\"[INFO] {} total frames in video\".format(total))\n",
    "except:\n",
    "    print(\"[INFO] could not determine # of frames in video\")\n",
    "    print(\"[INFO] no approx. completion time can be provided\")\n",
    "    total = -1\n",
    "\n",
    "model = load_model('yolo-keras.h5')  # y2k.Yolov3_Keras(WEIGHTS_PATH)\n",
    "\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    (grabbed, frame) = vs.read()\n",
    "    initial_frame = frame\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "    # adapt the frame to the yolov3 network architecture\n",
    "    frame = cv2.resize(frame, (YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "    frame = frame.astype('float32')\n",
    "    frame /= 255.0\n",
    "    frame = np.expand_dims(frame, 0)\n",
    "\n",
    "    yhat = model.predict(frame)\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        boxes += utils.decode_netout(yhat[i][0], YOLOV3_ANCHORS[i], CLASS_THRESHOLD,\n",
    "                                     YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT)\n",
    "\n",
    "    utils.correct_yolo_boxes(boxes, H, W, YOLOV3_INPUT_WIDTH, YOLOV3_INPUT_HEIGHT)\n",
    "\n",
    "    utils.do_nms(boxes, NMS_THRESHOLD)\n",
    "\n",
    "    v_boxes, v_labels, v_scores = utils.get_boxes(boxes, LABELS, CLASS_THRESHOLD)\n",
    "\n",
    "    for i in range(len(v_boxes)):\n",
    "        if v_labels[i] == 'person':\n",
    "                box = v_boxes[i]\n",
    "                y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "                width, height = x2 - x1, y2 - y1\n",
    "\n",
    "                color = [int(c) for c in COLORS[LABELS.index(v_labels[i])]]  # COLORS[LABELS.index(v_labels[i])]\n",
    "                cv2.rectangle(initial_frame, (x1, y1), (x1 + width, y1 + height), color, 2)\n",
    "                text = \"%s (%.4f)\" % (v_labels[i], v_scores[i])\n",
    "                cv2.putText(initial_frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    if writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(OUTPUT_FILE, fourcc, 30,\n",
    "                                 (initial_frame.shape[1], initial_frame.shape[0]), True)\n",
    "\n",
    "    writer.write(initial_frame)\n",
    "print(\"[INFO] cleaning up...\")\n",
    "print(\"[INFO] total time = %.2f\" % (time.time() - start_time))\n",
    "writer.release()\n",
    "vs.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_virtenv",
   "language": "python",
   "name": "yolo_virtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
